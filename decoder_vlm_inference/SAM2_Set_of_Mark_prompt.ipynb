{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# SAM 2のインストール\n",
        "!git clone https://github.com/facebookresearch/segment-anything-2.git\n",
        "%cd segment-anything-2\n",
        "!pip install -e .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEo37LO2RvTB",
        "outputId": "34d5be6a-0ac5-4114-f79c-3eaec394086a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'segment-anything-2'...\n",
            "remote: Enumerating objects: 1070, done.\u001b[K\n",
            "remote: Total 1070 (delta 0), reused 0 (delta 0), pack-reused 1070 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1070/1070), 128.11 MiB | 13.88 MiB/s, done.\n",
            "Resolving deltas: 100% (380/380), done.\n",
            "/content/segment-anything-2\n",
            "Obtaining file:///content/segment-anything-2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (4.67.1)\n",
            "Collecting hydra-core>=1.3.2 (from SAM-2==1.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting iopath>=0.1.10 (from SAM-2==1.0)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (11.2.1)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (24.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.10->SAM-2==1.0) (4.14.0)\n",
            "Collecting portalocker (from iopath>=0.1.10->SAM-2==1.0)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.1->SAM-2==1.0) (1.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core>=1.3.2->SAM-2==1.0) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->SAM-2==1.0) (3.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: SAM-2, iopath\n",
            "  Building editable for SAM-2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for SAM-2: filename=sam_2-1.0-0.editable-cp311-cp311-linux_x86_64.whl size=13863 sha256=a796a8f935ae2e49b4e03da92462fa0001ef2e99acaff988eb8023e1524bfc10\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-o76x65c4/wheels/79/7c/e1/0da3f0d4adfcc74ea4d1578b1a77a5a1647d6dc06af87a30e7\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=c53bc9f8b9a4becc65d91e2ad3a0a2cc00949f3df0aa0b0295eb42e4d0b281cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built SAM-2 iopath\n",
            "Installing collected packages: portalocker, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, iopath, hydra-core, nvidia-cusolver-cu12, SAM-2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed SAM-2-1.0 hydra-core-1.3.2 iopath-0.1.10 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 portalocker-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download models\n",
        "# 他のモデルはこちら：https://github.com/facebookresearch/sam2?tab=readme-ov-file#model-description\n",
        "# もしくはcheckpoints/download_ckpts.shから\n",
        "\n",
        "!wget https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt -O checkpoints/sam2.1_hiera_large.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPsga4OESOx-",
        "outputId": "81026577-5561-438a-acef-19a8e4f72338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-22 22:29:37--  https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.226.210.111, 13.226.210.15, 13.226.210.25, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.226.210.111|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 898083611 (856M) [application/vnd.snesdev-page-table]\n",
            "Saving to: ‘checkpoints/sam2.1_hiera_large.pt’\n",
            "\n",
            "checkpoints/sam2.1_ 100%[===================>] 856.48M   140MB/s    in 6.0s    \n",
            "\n",
            "2025-06-22 22:29:43 (143 MB/s) - ‘checkpoints/sam2.1_hiera_large.pt’ saved [898083611/898083611]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import torch\n",
        "from sam2.build_sam import build_sam2\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
        "import os\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "class SAM2Segmentation:\n",
        "    def __init__(self, model_cfg=\"sam2_hiera_l.yaml\", checkpoint_path=\"sam2_hiera_large.pt\"):\n",
        "        \"\"\"\n",
        "        SAM2セグメンテーションクラス\n",
        "\n",
        "        Args:\n",
        "            model_cfg: モデル設定ファイルのパス\n",
        "            checkpoint_path: チェックポイントファイルのパス\n",
        "        \"\"\"\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"使用デバイス: {self.device}\")\n",
        "\n",
        "        # SAM2モデルの構築\n",
        "        self.sam2_model = build_sam2(model_cfg, checkpoint_path, device=self.device)\n",
        "\n",
        "        # 自動マスク生成器の初期化\n",
        "        self.mask_generator = SAM2AutomaticMaskGenerator(\n",
        "            model=self.sam2_model,\n",
        "            points_per_side=32,\n",
        "            pred_iou_thresh=0.7,\n",
        "            stability_score_thresh=0.92,\n",
        "            crop_n_layers=1,\n",
        "            crop_n_points_downscale_factor=2,\n",
        "            min_mask_region_area=100,\n",
        "        )\n",
        "\n",
        "    def load_image(self, image_path):\n",
        "        \"\"\"画像を読み込み、RGB形式で返す\"\"\"\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise ValueError(f\"画像を読み込めませんでした: {image_path}\")\n",
        "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    def generate_masks(self, image):\n",
        "        \"\"\"画像に対してセグメンテーションマスクを生成\"\"\"\n",
        "        print(\"セグメンテーションマスクを生成中...\")\n",
        "        masks = self.mask_generator.generate(image)\n",
        "        print(f\"生成されたマスク数: {len(masks)}\")\n",
        "        return masks\n",
        "\n",
        "    def draw_numbered_segments(self, image, masks, output_path=\"segmented_image.png\", font_size=None):\n",
        "        \"\"\"\n",
        "        セグメンテーション結果を可視化し、各領域に番号を印字\n",
        "\n",
        "        Args:\n",
        "            image: 元画像（RGB）\n",
        "            masks: セグメンテーションマスクのリスト\n",
        "            output_path: 出力画像のパス\n",
        "            font_size: フォントサイズ（Noneの場合は自動調整）\n",
        "        \"\"\"\n",
        "        # 結果画像の作成\n",
        "        result_image = image.copy()\n",
        "\n",
        "        # マスクを面積順にソート（大きい順）\n",
        "        sorted_masks = sorted(masks, key=lambda x: x['area'], reverse=True)\n",
        "\n",
        "        # カラーマップの作成\n",
        "        colors = plt.cm.tab20(np.linspace(0, 1, len(sorted_masks)))\n",
        "\n",
        "        # PIL画像に変換（テキスト描画のため）\n",
        "        pil_image = Image.fromarray(result_image)\n",
        "        draw = ImageDraw.Draw(pil_image)\n",
        "\n",
        "        # フォントサイズの設定\n",
        "        if font_size is None:\n",
        "            font_size = max(20, min(image.shape[0], image.shape[1]) // 30)\n",
        "\n",
        "        # フォントの取得を試行\n",
        "        font = None\n",
        "        font_candidates = [\n",
        "            \"arial.ttf\",\n",
        "            \"Arial.ttf\",\n",
        "            \"helvetica.ttf\",\n",
        "            \"DejaVuSans.ttf\",\n",
        "            \"NotoSans-Regular.ttf\",\n",
        "            \"calibri.ttf\",\n",
        "            \"Calibri.ttf\"\n",
        "        ]\n",
        "\n",
        "        # システムフォントを順番に試行\n",
        "        for font_name in font_candidates:\n",
        "            try:\n",
        "                font = ImageFont.truetype(font_name, font_size)\n",
        "                break\n",
        "            except (OSError, IOError):\n",
        "                continue\n",
        "\n",
        "        # システムフォントが見つからない場合はpillow-simsunを試行\n",
        "        if font is None:\n",
        "            try:\n",
        "                import PIL.ImageFont\n",
        "                # Pillowの内蔵フォントでサイズ指定可能なものを試行\n",
        "                font = ImageFont.load_default()\n",
        "                # load_default()は固定サイズなので、代替手段としてcv2で描画に変更\n",
        "                use_cv2_text = True\n",
        "            except:\n",
        "                use_cv2_text = True\n",
        "        else:\n",
        "            use_cv2_text = False\n",
        "\n",
        "        # 各マスクを処理\n",
        "        for i, mask_info in enumerate(sorted_masks):\n",
        "            mask = mask_info['segmentation']\n",
        "            color = colors[i % len(colors)]\n",
        "\n",
        "            # マスクの重ね合わせ（半透明）\n",
        "            mask_colored = np.zeros_like(result_image)\n",
        "            mask_colored[mask] = (np.array(color[:3]) * 255).astype(np.uint8)\n",
        "\n",
        "            # アルファブレンド\n",
        "            alpha = 0.3\n",
        "            result_image = cv2.addWeighted(result_image, 1-alpha, mask_colored, alpha, 0)\n",
        "\n",
        "            # マスクの重心を計算\n",
        "            y_coords, x_coords = np.where(mask)\n",
        "            if len(y_coords) > 0:\n",
        "                centroid_x = int(np.mean(x_coords))\n",
        "                centroid_y = int(np.mean(y_coords))\n",
        "\n",
        "                # 番号を描画\n",
        "                text = str(i + 1)\n",
        "\n",
        "                if use_cv2_text:\n",
        "                    # OpenCVでテキスト描画の場合は一時的にPIL画像をnumpy配列に変換\n",
        "                    temp_array = np.array(pil_image)\n",
        "\n",
        "                    # OpenCVでテキスト描画（フォントサイズをスケールで調整）\n",
        "                    font_scale = font_size / 30.0  # 30を基準とした相対スケール\n",
        "                    thickness = max(1, int(font_size / 15))  # 太さも調整\n",
        "\n",
        "                    # テキストサイズを取得\n",
        "                    (text_width, text_height), baseline = cv2.getTextSize(\n",
        "                        text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness\n",
        "                    )\n",
        "\n",
        "                    # 背景円を描画\n",
        "                    circle_radius = max(text_width, text_height) // 2 + int(font_size * 0.3)\n",
        "                    cv2.circle(temp_array, (centroid_x, centroid_y), circle_radius, (255, 255, 255), -1)\n",
        "                    cv2.circle(temp_array, (centroid_x, centroid_y), circle_radius, (0, 0, 0), 2)\n",
        "\n",
        "                    # テキストの位置を調整\n",
        "                    text_x = centroid_x - text_width // 2\n",
        "                    text_y = centroid_y + text_height // 2\n",
        "\n",
        "                    # 番号を描画\n",
        "                    cv2.putText(temp_array, text, (text_x, text_y),\n",
        "                               cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), thickness)\n",
        "\n",
        "                    # PIL画像を更新\n",
        "                    pil_image = Image.fromarray(temp_array)\n",
        "                    draw = ImageDraw.Draw(pil_image)\n",
        "                else:\n",
        "                    # PILでテキスト描画（True Type フォント使用）\n",
        "                    # テキストの境界ボックスを取得\n",
        "                    bbox = draw.textbbox((0, 0), text, font=font)\n",
        "                    text_width = bbox[2] - bbox[0]\n",
        "                    text_height = bbox[3] - bbox[1]\n",
        "\n",
        "                    # テキストの位置を調整\n",
        "                    text_x = centroid_x - text_width // 2\n",
        "                    text_y = centroid_y - text_height // 2\n",
        "\n",
        "                    # 背景円を描画\n",
        "                    circle_radius = max(text_width, text_height) // 2 + 5\n",
        "                    draw.ellipse(\n",
        "                        [(centroid_x - circle_radius, centroid_y - circle_radius),\n",
        "                         (centroid_x + circle_radius, centroid_y + circle_radius)],\n",
        "                        fill=(255, 255, 255, 200),\n",
        "                        outline=(0, 0, 0, 255),\n",
        "                        width=2\n",
        "                    )\n",
        "\n",
        "                    # 番号を描画\n",
        "                    draw.text((text_x, text_y), text, fill=(0, 0, 0, 255), font=font)\n",
        "\n",
        "        # 最終的にPIL画像をnumpy配列に変換\n",
        "        result_image = np.array(pil_image)\n",
        "\n",
        "        # 結果を保存\n",
        "        cv2.imwrite(output_path, cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR))\n",
        "        print(f\"結果画像を保存しました: {output_path}\")\n",
        "\n",
        "        return result_image\n",
        "\n",
        "    def create_mask_overlay(self, image, masks, output_path=\"mask_overlay.png\"):\n",
        "        \"\"\"マスクオーバーレイ画像を作成\"\"\"\n",
        "        overlay = np.zeros_like(image)\n",
        "\n",
        "        for i, mask_info in enumerate(masks):\n",
        "            mask = mask_info['segmentation']\n",
        "            color = plt.cm.tab20(i / len(masks))[:3]\n",
        "            overlay[mask] = (np.array(color) * 255).astype(np.uint8)\n",
        "\n",
        "        # 元画像と重ね合わせ\n",
        "        result = cv2.addWeighted(image, 0.7, overlay, 0.3, 0)\n",
        "        cv2.imwrite(output_path, cv2.cvtColor(result, cv2.COLOR_RGB2BGR))\n",
        "        print(f\"マスクオーバーレイ画像を保存しました: {output_path}\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    def save_mask_info(self, masks, output_path=\"mask_info.json\"):\n",
        "        \"\"\"マスク情報をJSONファイルに保存\"\"\"\n",
        "        import json\n",
        "\n",
        "        # JSONに保存するデータを準備\n",
        "        mask_data = {\n",
        "            \"total_segments\": len(masks),\n",
        "            \"segments\": []\n",
        "        }\n",
        "\n",
        "        for i, mask_info in enumerate(masks):\n",
        "            segment_info = {\n",
        "                \"segment_id\": i + 1,\n",
        "                \"area\": int(mask_info['area']),\n",
        "                \"predicted_iou\": float(mask_info['predicted_iou']),\n",
        "                \"stability_score\": float(mask_info['stability_score']),\n",
        "                \"bbox\": {\n",
        "                    \"x\": int(mask_info['bbox'][0]),\n",
        "                    \"y\": int(mask_info['bbox'][1]),\n",
        "                    \"width\": int(mask_info['bbox'][2]),\n",
        "                    \"height\": int(mask_info['bbox'][3])\n",
        "                }\n",
        "            }\n",
        "\n",
        "            # 重心座標を計算\n",
        "            mask = mask_info['segmentation']\n",
        "            y_coords, x_coords = np.where(mask)\n",
        "            if len(y_coords) > 0:\n",
        "                centroid = {\n",
        "                    \"x\": float(np.mean(x_coords)),\n",
        "                    \"y\": float(np.mean(y_coords))\n",
        "                }\n",
        "                segment_info[\"centroid\"] = centroid\n",
        "\n",
        "            mask_data[\"segments\"].append(segment_info)\n",
        "\n",
        "        # JSONファイルに保存\n",
        "        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(mask_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        print(f\"マスク情報をJSONで保存しました: {output_path}\")\n",
        "\n",
        "    def process_image(self, image_path, output_dir=\"output\", font_size=None):\n",
        "        \"\"\"\n",
        "        画像を処理してセグメンテーション結果を出力\n",
        "\n",
        "        Args:\n",
        "            image_path: 入力画像のパス\n",
        "            output_dir: 出力ディレクトリ\n",
        "            font_size: 印字する数字のフォントサイズ（Noneの場合は自動調整）\n",
        "        \"\"\"\n",
        "        # 出力ディレクトリの作成\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # 画像の読み込み\n",
        "        image = self.load_image(image_path)\n",
        "        print(f\"画像サイズ: {image.shape}\")\n",
        "\n",
        "        # セグメンテーション実行\n",
        "        masks = self.generate_masks(image)\n",
        "\n",
        "        # 結果の可視化と保存\n",
        "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "        # 番号付きセグメンテーション画像\n",
        "        numbered_output = os.path.join(output_dir, f\"{base_name}_numbered.png\")\n",
        "        self.draw_numbered_segments(image, masks, numbered_output, font_size=font_size)\n",
        "\n",
        "        # マスクオーバーレイ画像\n",
        "        overlay_output = os.path.join(output_dir, f\"{base_name}_overlay.png\")\n",
        "        self.create_mask_overlay(image, masks, overlay_output)\n",
        "\n",
        "        # マスク情報の保存（JSON形式）\n",
        "        info_output = os.path.join(output_dir, f\"{base_name}_info.json\")\n",
        "        self.save_mask_info(masks, info_output)\n",
        "\n",
        "        return masks\n",
        "\n"
      ],
      "metadata": {
        "id": "z62jKALFgXGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用例\n",
        "\n",
        "# SAM2セグメンテーションオブジェクトの作成\n",
        "# 注意: 実際のモデルファイルのパスを指定してください\n",
        "segmenter = SAM2Segmentation(\n",
        "    model_cfg=\"configs/sam2.1/sam2.1_hiera_l.yaml\",  # 設定ファイルのパス\n",
        "    checkpoint_path=\"checkpoints/sam2.1_hiera_large.pt\"  # チェックポイントのパス\n",
        ")\n",
        "# 画像のパスを指定\n",
        "image_path = \"/content/a3c3w3.jpg\"  # 処理したい画像のパス\n",
        "\n",
        "# セグメンテーション実行\n",
        "try:\n",
        "    masks = segmenter.process_image(image_path, output_dir=\"segmentation_results\", font_size=20)  # フォントサイズを指定（例：40px）\n",
        "    print(f\"処理完了! {len(masks)}個の領域が検出されました。\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"エラーが発生しました: {e}\")\n",
        "    print(\"以下を確認してください:\")\n",
        "    print(\"1. SAM2モデルファイルが正しいパスに配置されているか\")\n",
        "    print(\"2. 入力画像が存在するか\")\n",
        "    print(\"3. 必要なライブラリがインストールされているか\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXqwoKc8Rovk",
        "outputId": "70e8609e-8616-4a9e-b0eb-88697ba77610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用デバイス: cuda\n",
            "画像サイズ: (1024, 1024, 3)\n",
            "セグメンテーションマスクを生成中...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/segment-anything-2/sam2/sam2_image_predictor.py:431: UserWarning: /content/segment-anything-2/sam2/_C.so: undefined symbol: _ZN3c106detail23torchInternalAssertFailEPKcS2_jS2_RKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
            "\n",
            "Skipping the post-processing step due to the error above. You can still use SAM 2 and it's OK to ignore the error above, although some post-processing functionality may be limited (which doesn't affect the results in most cases; see https://github.com/facebookresearch/sam2/blob/main/INSTALL.md).\n",
            "  masks = self._transforms.postprocess_masks(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "生成されたマスク数: 21\n",
            "結果画像を保存しました: segmentation_results/a3c3w3_numbered.png\n",
            "マスクオーバーレイ画像を保存しました: segmentation_results/a3c3w3_overlay.png\n",
            "マスク情報をJSONで保存しました: segmentation_results/a3c3w3_info.json\n",
            "処理完了! 21個の領域が検出されました。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "注意：初回実行時に以下の警告が出るのを確認しています。\n",
        "おそらくはPyTorchのバージョンが適していないゆえの警告かと思います。今回は十分目的の動作はできているのでこのまま進めさせてください。後日原因が確認でき次第修正したいと思います。（2025.06.23 品川）\n",
        "\n",
        "/content/segment-anything-2/sam2/sam2_image_predictor.py:431: UserWarning: /content/segment-anything-2/sam2/_C.so: undefined symbol: _ZN3c106detail23torchInternalAssertFailEPKcS2_jS2_RKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
        "\n",
        "Skipping the post-processing step due to the error above. You can still use SAM 2 and it's OK to ignore the error above, although some post-processing functionality may be limited (which doesn't affect the results in most cases; see https://github.com/facebookresearch/sam2/blob/main/INSTALL.md)."
      ],
      "metadata": {
        "id": "hwXmtc8Yx07P"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GHwqTThUzfaz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}